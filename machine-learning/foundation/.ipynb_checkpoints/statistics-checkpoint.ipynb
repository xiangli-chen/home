{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics\n",
    "\n",
    "Table of Contents\n",
    "\n",
    "- [Empirical distribution](#empirical)\n",
    "- [Confidence interval](#conf)\n",
    "- [Frequentist statistics](#freq)\n",
    " - [Maximum likelihood estimation](#mle)\n",
    " - [Expectation and maximization algorithm](#em)\n",
    "- [Bayesian statistics](#bayesian)\n",
    "- [Bootstrap](#bootstrap)\n",
    "- [Summary](#summary)\n",
    "- [References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirical distribution <a name='empirical'></a>\n",
    "**Empirical distribution**   \n",
    "Definition  \n",
    "Let $X_1,\\ldots,X_n$ i.i.d., $F(t) = p(x_i\\leq t)$. The empirical distribution function (empirical cumulative distribution function), is defined as\n",
    "$$\\hat{F}_n(t) = \\frac{1}{n}\\sum_{i=1}^n 1_{(X_i\\leq t)}$$\n",
    "where $1$ is the indicator function. Note that for a fixed $t$, $F(t)$ is a constant and $\\hat{F}_n(t)$ is a function of $X_1,\\ldots,X_n$.  \n",
    "\n",
    "- Pointwise convergence (for fixed t)  \n",
    "  - Hoeffding's inequality implies that for any $\\epsilon > 0$, \n",
    "  $$p(\\left|\\hat{F}_n(t) - F(t)\\right| \\geq \\epsilon) \\leq 2e^{-2n\\epsilon^2},$$ \n",
    "  so $$\\hat{F}_n(t) \\buildrel p \\over \\rightarrow F(t).$$\n",
    "  - Note that $\\mathbb{E}[|1_{(X_i\\leq t)}|]<\\infty$ and $\\mathbb{E}[1_{(X_i\\leq t)}] = F(t)$, strong law of large numbers implies that \n",
    "  $$\\hat{F}_n(t) \\buildrel a.s. \\over \\rightarrow F(t).$$\n",
    "- Uniformly convergence\n",
    "  - Glivenko-Cantelli Lemma. The empirical distribution converges uniformly to $F(x)$, namely \n",
    "  $$\\sup_{t \\in \\mathbb{R}} \\left|\\hat{F}_n(t) - F(t)\\right| \\buildrel a.s. \\over \\rightarrow 0.$$\n",
    "  - Dvoretzky-Kiefer-Wolfowith (DKW) inequality. For any $\\epsilon > 0$ and any $n > 0$\n",
    "  $$p(\\sup_{x\\in \\mathbb{R}}\\left|\\hat{F}_n(t) - F(t)\\right|\\geq \\epsilon) \\leq 2e^{-2n\\epsilon^2}.$$\n",
    "  \n",
    "**Empirical measure** (probability)  \n",
    "The empirical measure $p_n$ is defined by\n",
    "$$\\hat{p}_{n}(A)=\\frac{1}{n}\\sum_{i=1}^{n} I_{(X_i\\in A)}=\\frac{1}{n}\\sum _{i=1}^{n}\\delta_{X_i}(A)$$\n",
    "where $I_{A}$ is the indicator function and $\\delta_{X}$ is the Dirac measure.  \n",
    "\n",
    "Given a random sample, there may be repeated values, we can express empirical measure \n",
    "as **relative frequency**\n",
    "$$p_{i}={\\frac{n_i}{N}}={\\frac{n_i}{\\sum_{j}n_j}}.$$\n",
    "- It can be proved that relative frequencies is a sufficient statistic for the true distribution.\n",
    "It means all the information about the true distribution in a sample is also contained in the relative frequencies. \n",
    "\n",
    "**Plug-in estimator**  \n",
    "The plug-in estimate of a parameter $\\theta = T(p)$ is defined to be $\\hat{\\theta}_n = T(\\hat{p}_n)$.  \n",
    "Examples\n",
    "Given a random sample $x_1,\\ldots, x_n$,\n",
    "- The plug-in estimator of mean $\\mu$,\n",
    "$$\\hat{\\mu} = \\mathbb{E}_{\\hat{p}_n}[X] = \\frac{1}{n}\\sum_{i=1}^n x_i.$$\n",
    "It is unbiased and consistent.\n",
    "- The plug-in estimator of variance $\\sigma^2$,\n",
    "$$\\hat{\\sigma}^2 = \\mathbb{E}_{\\hat{p}_n}[(X-\\mathbb{E}_{\\hat{p}_n}[X])^2]=\\frac{1}{n}\\sum_{i=1}^n (x_i-\\bar{x})^2.$$\n",
    "It is biased and consistent. The sample variance\n",
    "$$\\frac{1}{n-1}\\sum_{i=1}^n (x_i-\\bar{x})^2$$\n",
    "is unbiased."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence interval <a name='conf'></a>\n",
    "[//]: # (comment) \n",
    "**Definition**     \n",
    "Let $X_1,\\ldots,X_n$ be a sample on $X\\sim f(x;\\theta), \\theta\\in\\Omega$.\n",
    "Let $L=L(X_1,\\ldots,X_n)$ and $U=U(X_1,\\ldots,X_n)$ be two statistics and $0<\\alpha<1$.\n",
    "The interval $(L,U)$ is a $(1-\\alpha)100\\%$ confidence interval for $\\theta$ if\n",
    "$$1-\\alpha=p_{\\theta}(\\theta\\in(L,U)).$$\n",
    "\n",
    "Some examples  \n",
    "Let sample mean $\\overline{X}_n = \\frac{1}{n}\\sum_{i=1}^n X_i$ and\n",
    "sample variance $S_n^2 = \\frac{1}{n-1}\\sum_{i=1}^n(X_i-\\overline{X})^2$. \n",
    "- Confidence interval under normality  \n",
    "$X_1,\\ldots,X_n$ i.i.d. $X_i\\sim N(\\mu,\\sigma^2)$,\n",
    "  - confidence interval for $\\mu$ when $\\sigma^2$ is known\n",
    "  We know $T = \\frac{\\overline{X}_n-\\mu}{\\sigma/\\sqrt{n}} \\sim N(0,1)$,\n",
    "  $$ 1-\\alpha = p\\left(\\overline{X}_n - z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}} < \\mu < \\overline{X}_n + z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}} \\right).$$\n",
    "  - Confidence interval for $\\mu$ when $\\sigma^2$ is unknown   \n",
    "  We know $T = \\frac{\\overline{X}_n-\\mu}{S_n/\\sqrt{n}} \\sim t(n-1)$,\n",
    "  $$1-\\alpha = p\\left(\\overline{x}_n-t_{\\alpha/2,n-1} \\frac{S_n}{\\sqrt{n}}<\\mu<\\overline{x}_n+t_{\\alpha/2,n-1} \\frac{S_n}{\\sqrt{n}}\\right).$$\n",
    "\n",
    "- Large sample confidence interval\n",
    "  - Large sample confidence interval for $\\mu$  \n",
    "  $X_1,\\ldots,X_n$ iid, $X_i$ has mean $\\mu$ and variance $\\sigma^2$. We know $\\frac{\\overline{X}_n-\\mu}{S/\\sqrt{n}} \\buildrel D\\over\\rightarrow Z=N(0,1)$, \n",
    "$$1-\\alpha \\approx p\\left(\\overline{x}-z_{\\alpha/2} \\frac{S_n}{\\sqrt{n}}<\\mu<\n",
    "\\overline{x}+z_{\\alpha/2} \\frac{S_n}{\\sqrt{n}}\\right).$$\n",
    "  - Large sample confidence interval for $p$ of $\\text{ber}(p)$  \n",
    "$X_1,\\ldots,X_n$ iid, $X_i\\sim \\text{ber}(p)$. Note that $\\mathbb{E}[X_i]=p$ and $\\text{Var}[X_i]=p(1-p)$.\n",
    "Let $\\hat{p}_n=\\overline{X}$, by CLT,\n",
    "$$\\frac{\\hat{p}-p}{\\sqrt{p(1-p)/n}} \\buildrel D\\over\\rightarrow Z=N(0,1).$$ \n",
    "Since $\\hat{p}_n \\buildrel D\\over\\rightarrow p$, we replace $p$ with $\\hat{p}_n$,\n",
    "$$\\frac{\\hat{p}_n-p}{\\sqrt{\\hat{p}_n(1-\\hat{p}_n)/n}} \\buildrel D\\over\\rightarrow Z=N(0,1),$$ \n",
    "and then\n",
    "$$1-\\alpha\\approx p\\left(\\hat{p}-z_{\\alpha/2}\\sqrt{\\hat{p}(1-\\hat{p})/n}<p<\n",
    "\\hat{p}+z_{\\alpha/2}\\sqrt{\\hat{p}(1-\\hat{p})/n}\\right).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequentist statistics <a name='freq'></a>\n",
    "### Maximum likelihood estimation <a name='mle'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expectation and maximization algorithm <a name='em'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian statistics <a name='bayesian'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap <a name='bootstrap'></a>\n",
    "**Bootstrap** is a data-based simulation method for statistical inference.\n",
    "Bootstrap provides a **general** method that allows assigning measures of accuracy to sample estimates. \n",
    "- doesn't matter about the measure. These measures may be defined in terms of bias, variance, confidence intervals, prediction error or some other such measures.\n",
    "- doesn't assume any assumption beyond sample.\n",
    "\n",
    "**Basic Procedure of bootstrap**  \n",
    "Given a random sample $X = (x_1, \\dots, x_n)$,\n",
    "- draw a sample $X^*_b = (x^*_1, \\ldots, x^*_n)$ with replacement from the random sample $X$ (or we can say draw from the empirical measure $\\hat{p}_n$) many times (say $B$ times).\n",
    "- do statistical inference with theses samples $(X^*_1, \\ldots, X^*_B)$.\n",
    "\n",
    "### Estimate of standard error\n",
    "We want to evaluate the quality of a statistics of a random sample $\\hat{\\theta} = T(x_1, \\ldots, x_n)$ by its standard error.\n",
    "\n",
    "### Estimate of bias\n",
    "\n",
    "### Confidence intervals\n",
    "\n",
    "### Prediction error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary <a name='summary'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
