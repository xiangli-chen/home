{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivative \n",
    "**Derivative** of univariate function: \n",
    "$$\n",
    "\\frac{df(x)}{dx} = \\lim_{\\Delta x\\ \\to 0} \\frac{f(x + \\Delta x) - f(x)}{\\Delta x}.\n",
    "$$\n",
    "The derivate tells us how sensitive of $f(x)$ on $x$.  \n",
    "**Partial Derivative** of multivariate function:\n",
    "$$\n",
    "\\frac{\\partial f(x,y)}{\\partial x} = \\lim_{\\Delta x\\ \\to 0} \\frac{f(x + \\Delta x, y) - f(x, y)}{\\Delta x}.\n",
    "$$\n",
    "The partial derivate with respect to $x$ tells us how sensitive of $f(x,y)$ on $x$ given a value of $y$.  \n",
    "**Chain Rule**   \n",
    "Univeriate case  \n",
    "Suppose $u=\\phi(x)$ and $v=\\psi(x)$, under some conditions, then\n",
    "$$\n",
    "\\frac{df(\\phi(x),\\psi(x))}{dx}=\n",
    "\\frac{\\partial f(u,v)}{\\partial u}\\frac{d\\phi(x)}{dx}+\n",
    "\\frac{\\partial f(u,v)}{\\partial v}\\frac{d\\psi(x)}{dx}.\n",
    "$$\n",
    "Multivariate case  \n",
    "Suppose $u=\\phi(x,y)$ and $v=\\psi(x,y)$, under some conditions, then\n",
    "$$\n",
    "\\frac{\\partial f(\\phi(x,y),\\psi(x,y))}{\\partial x}=\n",
    "\\frac{\\partial f(u,v)}{\\partial u}\\frac{\\partial \\phi(x,y)}{\\partial x}+\n",
    "\\frac{\\partial f(u,v)}{\\partial v}\\frac{\\partial \\psi(x,y)}{\\partial x}.\n",
    "$$\n",
    "A special case, suppose $u=\\phi(x,y)$, $v=\\psi(x)$ and $w=\\omega(y)$, under some conditions, then\n",
    "$$\n",
    "\\frac{\\partial f(\\phi(x,y),\\psi(x),\\omega(y),x,y)}{\\partial x}=\n",
    "\\frac{\\partial f(u,v,w,x,y)}{\\partial u}\\frac{\\partial \\phi(x,y)}{\\partial x}+\n",
    "\\frac{\\partial f(u,v,w,x,y)}{\\partial v}\\frac{d\\psi(x)}{dx}+\n",
    "\\frac{\\partial f(u,v,w,x,y)}{\\partial x}.\n",
    "$$\n",
    "Note that though $f(\\phi(x,y),\\psi(x),\\omega(y),x,y)=f(u,v,w,x,y)$, but their partial derivative with respect to $x$ are different.\n",
    "$\\partial f(\\phi(x,y),\\psi(x),\\omega(y),x,y)/\\partial x$ consider $y$ is a constant with respect to $x$, while $\\partial f(u,v,w,x,y)/\\partial x$ consider $u,v,w$ and $y$ are constants with respect to $x$.   \n",
    "Suppose $\\theta = (\\theta^1,\\cdots,\\theta^n)$, we may apply chain rule recursively to get the partial derivative $\\partial f(\\theta)/\\partial \\theta_i$ for $\\forall i\\in \\{1,\\cdots,n\\}$.  \n",
    "Belw is an example of using chain rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backprobagation\n",
    "### A simple example\n",
    "Suppose $q=\\phi(x,y)=x+y$ and $f(\\phi(x,y),z)=\\phi(x,y)*z=(x+y)*z$, so $f(\\phi(x,y),z)=f(q,z)=q*z$,\n",
    "$$\n",
    "\\frac{\\partial f(\\phi(x,y),z)}{\\partial x} = \\frac{\\partial f(q,z)}{\\partial q}\n",
    "\\frac{\\partial \\phi(x,y)}{\\partial x} = z\\times 1 = z\\\\\n",
    "\\frac{\\partial f(\\phi(x,y),z)}{\\partial x} = \\frac{\\partial f(q,z)}{\\partial q}\n",
    "\\frac{\\partial \\phi(x,y)}{\\partial x} = z\\times 1 = z\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.0, -4.0, 3]\n"
     ]
    }
   ],
   "source": [
    "# set some inputs\n",
    "x = -2; y = 5; z = -4\n",
    "\n",
    "# perform the forward pass\n",
    "q = x + y # q becomes 3\n",
    "f = q * z # f becomes -12\n",
    "\n",
    "# perform the backward pass (backpropagation) in reverse order:\n",
    "# first backprop through f = q * z\n",
    "dfdz = q # df/dz = q, so gradient on z becomes 3\n",
    "dfdq = z # df/dq = z, so gradient on q becomes -4\n",
    "# now backprop through q = x + y\n",
    "dfdx = 1.0 * dfdq # dq/dx = 1. And the multiplication here is the chain rule!\n",
    "dfdy = 1.0 * dfdq # dq/dy = 1\n",
    "print([dfdx, dfdy, dfdz])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computation above can be visualized with a circuit diagram:\n",
    "![circuit-simple](./figures/fd/circuit-simple.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient\n",
    "Let $e_l=(\\cos\\alpha,\\cos\\beta)$ be a **unit vector** of the direction $l$ on a 2-D plane $(x,y)$, then the **directional derivative** of $f(x,y)$ with respect to $l$ is\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial l} = \\lim_{t\\ \\to 0^+} \\frac{f(x + t\\cos\\alpha, y+t\\cos\\beta) - f(x, y)}{t}.\n",
    "$$\n",
    "Directional derivative tells us how sensitive of $f(x,y)$ on the direction $l$ defined by $e_l=(\\cos\\alpha,\\cos\\beta)$.  \n",
    "A theorem shows that\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial l} = \\frac{\\partial f(x,y)}{\\partial x}\\cos\\alpha+\n",
    "\\frac{\\partial f(x,y)}{\\partial y}\\cos\\beta\n",
    "$$\n",
    "The **gradient** \\\\(\\nabla f\\\\) of $f(x,y)$ is the vector of partial derivatives that \n",
    "$$\n",
    "\\nabla f = (\\frac{\\partial f(x,y)}{\\partial x}, \\frac{\\partial f(x,y)}{\\partial y}),\n",
    "$$ \n",
    "and then\n",
    "$$\n",
    "\\frac{\\partial f}{\\partial l}=\\nabla f\\cdot e_l= |\\nabla||e_l|\\cos\\theta=|\\nabla|\\cos\\theta\n",
    "$$\n",
    "where $\\theta$ is the angle between $\\nabla f$ and $e_l$.   \n",
    "So when $\\theta = 0$ that $\\nabla f$ and $e_l$ have the same direction, the partial derivative are maximized which motivates the gradient learning method.\n",
    "Gradient is the most efficient direction for converging to an optimal point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
